# Phylogenetic-Diversity-across-the-complete-tree-of-life

Here I provide codes to run the functions, read in the original tables include ordered_leaves, ordered_nodes and the json field collected from Open Tree of Life, calculate evolutionary distinctiveness and phylogenetic diversity.

#read_json_get_date_dataframe 
The json field comes from the Open Tree of Life in which each one or two OTT_IDs have a date estimate. The #read_json_get_date_dataframe field will help us to find corresponding node ID for those date estimates and generate a table named "latest_node_dates”.

#bootstrap_analysis
With the "latest_node_dates” table generated, #bootstrap_analysis can use this table to randomly select 50% of the node date estimates, use the selected date estimates to calculate ED scores and repeat this step for 100 times. That will output a table named "ed_bootstrap(100)". We also have scripts for submitting the bootstrap analysis to HPC cluster. These scripts include: ED_score_for_hpc.py, which can calculate ED score for the leaves table and return a list of ED score; driver.py, which can run the ED_score_for_hpc and collect its output; ED_data_collection1-10.sh, which can change the random seed for the ED_score_for_hpc.py and split the 100 times bootstrap process into 10 seperate process; and the merge_part.sh, which can merge the output of ED_data_collection1-10.sh into a dataframe of ED score. After the table of ED scores are generated through merge_part.sh, run the transpose_ed_table.py to generate a table of ED scores.

#pd_estimate_for_ordered_nodes 
This script will help us to calculate total PD for all the interior nodes across the tree of life based on the calculated ED scores. 

#phyloinfo_for_edge20_species
This script calculates cumulative ED value for each interior node of the top 20 EDGE species

#figures_script
This is a R script that can generate all the figures in this paper. Estimation of EDGE scores for those IUCN evaluated species is also given in this part.


detailed example of the inputs, outputs, and calculations.


#read_json_get_date_dataframe.py
The input file is the json data which comes from the Open Tree of Life. In this file, each one or two OTT_IDs have a date estimate. The original data looked like this: "mrcaott119219ott212182": [{"source_id": "ot_534@tree5", "age": 40.051873, "source_node": "node665"}, {"source_id": "ot_409@tree1", "age": 54.020365, "source_node": "node18041"}], "mrcaott12995ott26078": [{"source_id": "ot_534@tree5", "age": 56.874824000000004, "source_node": "node606"}, {"source_id": "ot_809@tree2", "age": 69.623766, "source_node": "node23454"}, {"source_id": "ot_534@tree7", "age": 58.020022, "source_node": "node892"}, {"source_id": "ot_531@tree1", "age": 58.414834, "source_node": "node127"}]. The information we need is ott_ID and date estimates: mrcaott119219ott212182, {“age”: [40.051873, 54.020365,]}; mrcaott12995ott26078, {“age”: [56.874824000000004, 69.623766, 58.020022, 58.414834]}.
In this part, ott_ID comes from the Open Tree of Life, leaf_ID and node_ID comes from the leaves_table and nodes_table generated by the OneZoom.
 
First, we deal with the list of date estimates that correspond to two ott_IDs.
In this data, if two ott ID have a list of date estimate, we will check whether these ott_IDs belongs to a leaves or nodes. Then, we will go through the leaves_table and nodes_table, which includes the structure information of the tree of life and find the most recent common ancestor of this two ott_ID. Note that this common ancestor must not be nodes that are generated from the randomly resolve process of the OneZoom. After checked this, we will give the list of date estimates to this most recent common ancestor.
 
Then, we deal with the list of date estimates that correspond to only one ott_ID. This indicates that this date estimates belongs to the node that has this ott_ID. Therefore, we directly give the date estimates to this node.
 
By running #read_json_get_date_dataframe, you will get a table of node date estimate in which each node id will have one or a list of node date estimates.
id                              ages
8474                            187.0
9559                            1222.4433330000000
60359                           2800.037518
60656                           2700.037518
60673                           1698.422916040978,1773.1541362005755,2150.037518,2150.037518

 
#bootstrap_analysis_for_ED_estimation.py
This script will calculate ED score for the entire leaves table. The input file of this script is a leaves table and a nodes table which includes the structural information of the tree of life (updated_ordered_nodes_2.0.csv, updated_ordered_leaves_2.0.csv), and the table of node date estimates generated by the #read_json_get_date_dataframe.py. Leaves here refer to species and nodes refer to ancestors.
 
In the #updated_ordered_nodes_2.0.csv, each node has a node ID, and a parent column shows its most recent common ancestor, and a real parent column to show whether this parent is generated through the random resolve process in OneZoom. Another important part is leaf_lft and leaf_rgt, these two columns will give us the exact number and species of the descendants of this node. By combining this table with the node date table (latest_node_dates(real_parent)_2.0.csv) generated by the previous step, we will have a complete node table includes both tree structural information and date estimates. The leaves table includes the name, leaf_ID and the ott_ID of this species. The leaf_ID will help us to relate this leaf with its parent node. The parent column shows its most recent common ancestor, and a real parent column to show whether this parent is generated by random resolving. These information can help us to estimate the ED score of a leaf.
 
To minimize the time of estimation, we first combined the leaves that have the same most recent common ancestor, because that means these two leaves will have the same ED score. For example, species A and B, D and E in this figure. The combined leaves table is named as leaves2 in the submitted code.
When we are calculating ED score, we have to overcome the data deficiency. For example, in this below figure, we only know the root of the tree of life is 4025 Myr ago, and the date estimate of node 2 is 50 Myr. We calculate ED based on the following step:
1.  	Create an empty list to store the weighted branch lengths ([])
2.  	For A and B, its terminal branch is 50 Myr, so we add this to the list. In ED estimation, the terminal branch connect the species to its most recent common ancestor does not need to be weighted. Now the list is [50].
3.  	Date estimate of node 1 is missing, so we keep finding its ancestor until we get a date estimate larger than 0. (In this example, it is the root of the tree of life, 4025 Myr).
4.  	We calculate the average branch length from the root to the node 2 to represent the branch length of Root-1 and 1-2, which is (4025-50)/2.
5.  	These two branches must be weighted by the number of species which are descended from it. For branch 1-2, its weighted length is 1/2*(4025-50)/2, and for branch Root-1, its weighted length is 1/3*(4025-50)/2
6.  	Now the list looks like: [662.5, 993.75, 50]. Sum of this list will give us the ED score of species A and B.
 
The code #bootstrap_analysis_for_ED_estimation.py can provide a quick check for ED estimation. By putting the script and the updated_ordered_nodes_2.0.csv, updated_ordered_leaves_2.0.csv and the latest_node_dates(real_parent)_2.0.csv in the same path and run the code, you can get a table of ED score. Every time calculating ED scores, we randomly through away 50% of node date estimates.
 
Calculate ED score for the entire leaves table repeatedly is time consuming, each repeat will take about 2.7 hours. Therefore, we also developed a version of codes for submitting to HPC. This includes three scripts: #ED_score_for_hpc.py, #ED_driver.py and #ED_data_collection1.sh. You can upload the three required files: updated_ordered_nodes_2.0.csv, updated_ordered_leaves_2.0.csv and the latest_node_dates(real_parent)_2.0.csv and the #ED_score_for_hpc.py, #ED_driver.py and #ED_data_collection1.sh to the cluster. The  ED_data_collection1.sh can change the random seed of the ED estimation script ED_score_for_hpc.py. By submitting several ED_data_collection1. sh to the HPC through (sbatch ED_data_collection_n.sh) with different set of random seeds (represented as arg_values in the ED_data_collection1.sh), you can process the repeat estimation step simultaneously. Then you can run the #ED_merge.sh to generate a table of ED scores named ED.csv. In this file, every row represents the ED scores generated by each replicate, and the number of columns is equal to the number of species in leaves2 (the leaves table which combined the species that have the same most recent common ancestor).
However, this file itself does not include species information. Therefore, you can run the code #ed_arrangement.py to give the calculated ED values to its corresponding leaves and now, you will have a table in which each leaves have multiple ED estimations generated during the replicate calculation.
 
#pd_estimate_for_ordered_nodes.py
Phylogenetic diversity (PD) is sum of the branch lengths included in a given clade. With all the ED scores estimated, it is easy to get the PD score of any  other clade. For example, the PD of clade A includes species A, B and C. The branches connect these species to the root of tree can be divided into three parts: all branches within this clade, a short branch connects this clade to the most recent ancestor of this clade, and a branch connect this clade to the root of the tree of life. By summing the ED score, we will have the length of branches included in this clade correctly. However, this is not equal to the total PD within this clade, because part of the branch connect to the root is also added. Therefore, subtract this part from the sum of the ED scores can give us the total PD included in this clade. We will use the below figure again for an example. Sum the ED score of A, B and C is 10.2, and the misadded branch connect clade A to the root is (2/5+3/3)*3 = 21/5. Therefore, use 10.2-21/5 and add a short branch connects this clade to the most recent ancestor of this clade, which is equal to 3 here will give us the total PD of this clade, 9 Myr, equal to the value we get by simply summing the branches: 1*2+1.5+2.5+3 = 9 Myr.
 
 
The script #pd_estimate_for_ordered_nodes.py is using this method to estimate PD for selected clades, with the same method to deal with data deficiency as in our ED estimation. The input file of this code is "updated_ordered_leaves_2.0.csv", "updated_ordered_nodes_2.0.csv", "ed_boostrap_new2(100).csv", and the "latest_node_dates(real_parent)_2.0.csv", all used or generated by the previous steps.
Our scripts estimate PD scores based on the following steps:
1.  	First, we combined the node table and the node date estimate table to generate a node table that include both node date estimate and tree structural information.
2.  	Then, we select 23 clades for PD estimation based on the node ID of the most recent common ancestor of this clade, and sum up the ED scores of all species included in this clade.
3.  	After that, we calculated the misadded branch connect this clade to the root. This part can be represented as the ED scores of this node multiplied by the species richness of this clade. Here we use the function defined as ed_node_realp to calculate the node ED score. The ED scores of this node multiplied by the species richness is defined as misadded PD.
4.  	Finally, we use the function age_for_unique_short_branch to find (or estimate if data deficient) the date estimate of the ancestor of the most recent common ancestor of the selected clade. The difference between this value and the date estimate of the most recent common ancestor of this clade can give us the length of the short branch connects this clade to the most recent ancestor of this clade. Subtracting the misadded PD from sum of ED scores, and add the unique short branch length will eventually give us the unique PD represented by this clade.


